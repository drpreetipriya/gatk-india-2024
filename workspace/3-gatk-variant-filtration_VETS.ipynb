{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lxWF2oIljvMi"
   },
   "source": [
    "# GATK Variant Filtration <a class=\"tocSkip\">\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FynFph92jvMk"
   },
   "source": [
    "**January 2024**\n",
    "\n",
    "<font size=4>This GATK tutorial will help you become familiar with using GATK tools to filter annotated variants. The notebook illustrates the following steps. \n",
    "\n",
    "- Use GATK to annotate a VCF with scores from an isolated forest model with Variant Extract-Train-Score (VETS) The higher the score, the more likely that the variant is real.\n",
    "- Use GATK to annotate a VCF with scores from a Convolutional Neural Network (CNN)\n",
    "- Generate 1D CNN models\n",
    "- Apply tranche filtering to VCF based on scores from an annotation in the INFO field\n",
    "- Calculate concordance metrics</font>\n",
    "\n",
    "_This tutorial was last tested with GATK v4.4.0 and IGV v2.8.0._ See [GATK Tool Documentation](https://gatk.broadinstitute.org/hc/en-us/articles/360037224712) for further information on the tools we use below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iPxdlVOHjvMk"
   },
   "source": [
    "# Set up your Notebook\n",
    "\n",
    "## Set cloud environment values\n",
    "If you opened this notebook and didn't adjust any cloud environment values, now's the time to edit them. Click on the gear icon in the upper right to edit your Cloud Environment form. Set the values as specified below:\n",
    "\n",
    "| Option | Value |\n",
    "| ------ | ------ |\n",
    "| Application Configuration | Custom Environment |\n",
    "| Container Image | us.gcr.io/broad-dsde-methods/gatk-workshop-terra-jupyter-image:1.0rc11 |\n",
    "| Creation Timeout Limit | 20 |\n",
    "| CPUs | 4 |\n",
    "| Memory | 15 GB |\n",
    "| Enable Autopause | True |\n",
    "| Minutes of Inactivity | 60 |\n",
    "| Disk size | 100 GB |\n",
    "\n",
    "\n",
    "Click the \"Update\" button when you are done, and Terra will begin to create a new runtime with your settings. When it is finished, it will pop up asking you to apply the new settings. In the meantime, you can continue with the setup instructions below. Note that because it is a custom image, this may take up to 10 minutes.\n",
    "\n",
    "## Check kernel type\n",
    "A kernel is a _computational engine_ that executes the code in the notebook. For this particular notebook, we will be using a custom Python 3 kernel so we can execute GATK commands using _Python Magic_ (`!`). \n",
    "\n",
    "To add your custom kernel to the notebook, go to the notebook's terminal, which you can find by clicking on the terminal icon at the bottom of the column to the far right of this notebook. You will be navigated to a new tab with your terminal. Type the command \"setup_gatk_env\" in the terminal, and hit enter. It will run for about 3 minutes and once it has printed that it has successfully installed, you can navigate back to this tab. You should now be able to set the Kernal from the Kernel menu in the upper left. \n",
    "Click on `Kernel` > `Change kernel` > `Python[conda env:gatkconda]`\n",
    "If you do not see this new custom option close and restart your Jupyter notebook\n",
    "\n",
    "In the upper right corner of the notebook, just under the Notebook Runtime, it should now say `Python[conda env:gatkconda]`. \n",
    "\n",
    "If you found the custom image and kernel instructions utterly confusing, navigate to a [more complete set of instructions with screenshots.](https://github.com/broadinstitute/gatk-workshop-terra-jupyter-image/wiki/Using-the-gatk%E2%80%90workshop%E2%80%90terra%E2%80%90jupyter%E2%80%90image-in-the-Terra-Jupyter-environment)\n",
    "\n",
    "## Set up your files\n",
    "Your notebook has a temporary folder that exists so long as your cluster is running. To see what files are in your notebook environment at any time, you can click on the Jupyter logo in the upper left corner. \n",
    "\n",
    "For this tutorial, we need to copy some files from this temporary folder to and from our workspace bucket. Run the two commands below to set up the workspace bucket variable and the file paths inside your notebook.\n",
    "\n",
    "<font color = \"green\"> **Tool Tip:** To run a cell in a notebook, press `SHIFT + ENTER`</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_GWaRo3tjvMl"
   },
   "outputs": [],
   "source": [
    "# Set your workspace bucket variable for this notebook.\n",
    "import os\n",
    "# BUCKET = os.environ['WORKSPACE_BUCKET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set workshop variable to access the most recent materials\n",
    "WORKSHOP = \"workshop_2002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a path we can reference for the rest of the notebook:\n",
    "RESOURCE_DIR = f\"gs://broad-dsde-methods-public/hg19\"\n",
    "BASE_DATA_DIR = f\"gs://gatk-tutorials/{WORKSHOP}\"\n",
    "LOCAL_DATA_DIR = \"/home/jupyter/notebooks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HAFDqnq0jvMo"
   },
   "outputs": [],
   "source": [
    "# Create directories for your files to live inside this notebook\n",
    "! mkdir -p $LOCAL_DATA_DIR/Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jpsakJxsjvMq"
   },
   "source": [
    "## Check data permissions\n",
    "For this tutorial, we have hosted the starting files in a public Google bucket. We will first check that the data is available to your user account, and if it is not, we simply need to install Google Cloud Storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4aXeUz8XjvMr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://gatk-tutorials/workshop_2002/2-germline/trio.ped\n",
      "gs://gatk-tutorials/workshop_2002/2-germline/CNNScoreVariants/\n",
      "gs://gatk-tutorials/workshop_2002/2-germline/bams/\n",
      "gs://gatk-tutorials/workshop_2002/2-germline/gvcfs/\n",
      "gs://gatk-tutorials/workshop_2002/2-germline/illumina_platinum/\n",
      "gs://gatk-tutorials/workshop_2002/2-germline/intervals/\n",
      "gs://gatk-tutorials/workshop_2002/2-germline/ref/\n",
      "gs://gatk-tutorials/workshop_2002/2-germline/resources/\n",
      "gs://broad-dsde-methods-public/hg19/\n",
      "gs://broad-dsde-methods-public/hg19/1000G_omni2.5.b37.chr20.vcf.gz\n",
      "gs://broad-dsde-methods-public/hg19/1000G_omni2.5.b37.chr20.vcf.gz.tbi\n",
      "gs://broad-dsde-methods-public/hg19/1000G_phase1.snps.high_confidence.b37.chr20.vcf.gz\n",
      "gs://broad-dsde-methods-public/hg19/1000G_phase1.snps.high_confidence.b37.chr20.vcf.gz.tbi\n",
      "gs://broad-dsde-methods-public/hg19/Axiom_Exome_Plus.genotypes.all_populations.poly.chr20.vcf.gz\n",
      "gs://broad-dsde-methods-public/hg19/Axiom_Exome_Plus.genotypes.all_populations.poly.chr20.vcf.gz.tbi\n",
      "gs://broad-dsde-methods-public/hg19/Homo_sapiens_assembly19.dbsnp138.chr20.vcf.gz\n",
      "gs://broad-dsde-methods-public/hg19/Homo_sapiens_assembly19.dbsnp138.chr20.vcf.gz.tbi\n",
      "gs://broad-dsde-methods-public/hg19/Homo_sapiens_assembly19.dict\n",
      "gs://broad-dsde-methods-public/hg19/Homo_sapiens_assembly19.fasta\n",
      "gs://broad-dsde-methods-public/hg19/Homo_sapiens_assembly19.fasta.fai\n",
      "gs://broad-dsde-methods-public/hg19/Mills_and_1000G_gold_standard.indels.b37.chr20.vcf.gz\n",
      "gs://broad-dsde-methods-public/hg19/Mills_and_1000G_gold_standard.indels.b37.chr20.vcf.gz.tbi\n",
      "gs://broad-dsde-methods-public/hg19/cytoBandIdeo.txt\n",
      "gs://broad-dsde-methods-public/hg19/gencode.v19.genes.v7.collapsed_only.patched_contigs.gtf.gz\n",
      "gs://broad-dsde-methods-public/hg19/gencode.v19.genes.v7.collapsed_only.patched_contigs.gtf.gz.tbi\n",
      "gs://broad-dsde-methods-public/hg19/gnomad.exomes.r2.1.1.sites.20.vcf.gz\n",
      "gs://broad-dsde-methods-public/hg19/gnomad.exomes.r2.1.1.sites.20.vcf.gz.tbi\n",
      "gs://broad-dsde-methods-public/hg19/gnomad.genomes.r2.1.1.sites.20.vcf.gz\n",
      "gs://broad-dsde-methods-public/hg19/gnomad.genomes.r2.1.1.sites.20.vcf.gz.tbi\n",
      "gs://broad-dsde-methods-public/hg19/hapmap_3.3.b37.chr20.vcf.gz\n",
      "gs://broad-dsde-methods-public/hg19/hapmap_3.3.b37.chr20.vcf.gz.tbi\n"
     ]
    }
   ],
   "source": [
    "# Check if data is accessible. The command should list several gs:// URLs.\n",
    "! gsutil ls $BASE_DATA_DIR/2-germline/\n",
    "! gsutil ls $RESOURCE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r5wR4GELjvMt"
   },
   "outputs": [],
   "source": [
    "# If you do not see gs:// URLs listed above, run this cell to install Google Cloud Storage. \n",
    "# Afterwards, restart the kernel with Kernel > Restart.\n",
    "#! pip install google-cloud-storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GItqUSbYjvMv"
   },
   "source": [
    "## Download Data to the Notebook \n",
    "Some tools are not able to read directly from a Google bucket, so we download their files to our local notebook folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1meW4GtMjvMw",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/sh: 1: time: not found\n",
      "\n",
      "/usr/bin/sh: 1: time: not found\n"
     ]
    }
   ],
   "source": [
    "# Start by downloading the base data:\n",
    "! time gsutil -m cp -r $BASE_DATA_DIR/2-germline $LOCAL_DATA_DIR/\n",
    "\n",
    "print()\n",
    "\n",
    "# Now download the other reference info:\n",
    "! time gsutil -m cp $RESOURCE_DIR/*.vcf.gz* $LOCAL_DATA_DIR/2-germline/resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's alias our variant file so we can just use it later:\n",
    "VCF_FILE = f\"{BASE_DATA_DIR}/2-germline/CNNScoreVariants/vcfs/g94982_b37_chr20_1m_15871.vcf.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the Variant Extract-Train-Score (VETS) on the VCF\n",
    "\n",
    "The Variant Extract-Train-Score (VETS) toolchain uses an isolation-forest model to flag probable artifacts.\n",
    "\n",
    "At a high-level, using this tool is a 3-step process:\n",
    "\n",
    "1. Extract the Variant Annotations\n",
    "2. Train the Variant Annotations Model\n",
    "3. Score the Variants\n",
    "\n",
    "This requires that you already have a set of variants that you have somehow validated which you can use to train the models.\n",
    "\n",
    "Note that because INDELs and SNPs have different inherent properties, they each require their own model.  This is also reflected in the known-variant datasets that are used to train the models. VETS creates both models at the same time as its default behavior and is used that way in this demo.\n",
    "\n",
    "In this example the variant calls to be filtered as well as the \"truth\" data are provided.\n",
    "\n",
    "For more information, see the [GATK Release Notes on VETS](https://github.com/broadinstitute/gatk/blob/ah_var_store/scripts/variantstore/docs/release_notes/VETS_Release.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the Variant Annotations\n",
    "\n",
    "Let's start by extracting the variants using the `ExtractVariantAnnotations`.\n",
    "\n",
    "Here we are using truth data from `hapmap`, `omni`, `1000 genomes`, `mills`, and `axiomPoly` to help train the models.  For this exercise the truth resource data has been truncated to only the region represented in our example data.\n",
    "\n",
    "The first three are best for SNP model training and the second two are best for INDEL model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GATK jar /gatk/gatk-package-4.5.0.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gatk/gatk-package-4.5.0.0-local.jar ExtractVariantAnnotations -mode SNP -mode INDEL -V gs://gatk-tutorials/workshop_2002/2-germline/CNNScoreVariants/vcfs/g94982_b37_chr20_1m_15871.vcf.gz -O /home/jupyter/notebooks/Output/output.extracted -A QD -A FS -A SOR -A MQRankSum -A ReadPosRankSum --resource:hapmap,training=true,calibration=true /home/jupyter/notebooks/2-germline/resources/hapmap_3.3.b37.chr20.vcf.gz --resource:omni,training=true,calibration=true /home/jupyter/notebooks/2-germline/resources/1000G_omni2.5.b37.chr20.vcf.gz --resource:1000G,training=true /home/jupyter/notebooks/2-germline/resources/1000G_phase1.snps.high_confidence.b37.chr20.vcf.gz --resource:mills,training=true,calibration=true /home/jupyter/notebooks/2-germline/resources/Mills_and_1000G_gold_standard.indels.b37.chr20.vcf.gz --resource:axiomPoly,training=true,calibration=true /home/jupyter/notebooks/2-germline/resources/Axiom_Exome_Plus.genotypes.all_populations.poly.chr20.vcf.gz\n",
      "04:58:32.062 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.5.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "04:58:32.231 INFO  ExtractVariantAnnotations - ------------------------------------------------------------\n",
      "04:58:32.235 INFO  ExtractVariantAnnotations - The Genome Analysis Toolkit (GATK) v4.5.0.0\n",
      "04:58:32.235 INFO  ExtractVariantAnnotations - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "04:58:32.235 INFO  ExtractVariantAnnotations - Executing as root@6fffd5f5c26a on Linux v6.5.11-linuxkit amd64\n",
      "04:58:32.235 INFO  ExtractVariantAnnotations - Java runtime: OpenJDK 64-Bit Server VM v17.0.9+9-Ubuntu-122.04\n",
      "04:58:32.236 INFO  ExtractVariantAnnotations - Start Date/Time: January 19, 2024 at 4:58:31 AM GMT\n",
      "04:58:32.236 INFO  ExtractVariantAnnotations - ------------------------------------------------------------\n",
      "04:58:32.236 INFO  ExtractVariantAnnotations - ------------------------------------------------------------\n",
      "04:58:32.239 INFO  ExtractVariantAnnotations - HTSJDK Version: 4.1.0\n",
      "04:58:32.239 INFO  ExtractVariantAnnotations - Picard Version: 3.1.1\n",
      "04:58:32.239 INFO  ExtractVariantAnnotations - Built for Spark Version: 3.5.0\n",
      "04:58:32.239 INFO  ExtractVariantAnnotations - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "04:58:32.239 INFO  ExtractVariantAnnotations - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "04:58:32.239 INFO  ExtractVariantAnnotations - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "04:58:32.240 INFO  ExtractVariantAnnotations - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "04:58:32.240 INFO  ExtractVariantAnnotations - Deflater: IntelDeflater\n",
      "04:58:32.240 INFO  ExtractVariantAnnotations - Inflater: IntelInflater\n",
      "04:58:32.240 INFO  ExtractVariantAnnotations - GCS max retries/reopens: 20\n",
      "04:58:32.240 INFO  ExtractVariantAnnotations - Requester pays: disabled\n",
      "04:58:32.240 WARN  ExtractVariantAnnotations - \n",
      "\n",
      "\u001b[1m\u001b[31m   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "   Warning: ExtractVariantAnnotations is a BETA tool and is not yet ready for use in production\n",
      "\n",
      "   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n",
      "\n",
      "\n",
      "04:58:32.241 INFO  ExtractVariantAnnotations - Initializing engine\n",
      "04:58:32.312 INFO  ExtractVariantAnnotations - Shutting down engine\n",
      "[January 19, 2024 at 4:58:32 AM GMT] org.broadinstitute.hellbender.tools.walkers.vqsr.scalable.ExtractVariantAnnotations done. Elapsed time: 0.01 minutes.\n",
      "Runtime.totalMemory()=101711872\n",
      "***********************************************************************\n",
      "\n",
      "A USER ERROR has occurred: Couldn't read file file:///home/jupyter/notebooks/2-germline/resources/hapmap_3.3.b37.chr20.vcf.gz. Error was: It doesn't exist.\n",
      "\n",
      "***********************************************************************\n",
      "Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.\n"
     ]
    }
   ],
   "source": [
    "! gatk ExtractVariantAnnotations \\\n",
    "    -mode SNP \\\n",
    "    -mode INDEL \\\n",
    "    -V $VCF_FILE \\\n",
    "    -O $LOCAL_DATA_DIR/Output/output.extracted \\\n",
    "    -A QD \\\n",
    "    -A FS \\\n",
    "    -A SOR \\\n",
    "    -A MQRankSum \\\n",
    "    -A ReadPosRankSum \\\n",
    "    --resource:hapmap,training=true,calibration=true $LOCAL_DATA_DIR/2-germline/resources/hapmap_3.3.b37.chr20.vcf.gz \\\n",
    "    --resource:omni,training=true,calibration=true $LOCAL_DATA_DIR/2-germline/resources/1000G_omni2.5.b37.chr20.vcf.gz \\\n",
    "    --resource:1000G,training=true $LOCAL_DATA_DIR/2-germline/resources/1000G_phase1.snps.high_confidence.b37.chr20.vcf.gz \\\n",
    "    --resource:mills,training=true,calibration=true $LOCAL_DATA_DIR/2-germline/resources/Mills_and_1000G_gold_standard.indels.b37.chr20.vcf.gz \\\n",
    "    --resource:axiomPoly,training=true,calibration=true $LOCAL_DATA_DIR/2-germline/resources/Axiom_Exome_Plus.genotypes.all_populations.poly.chr20.vcf.gz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Variant Annotations\n",
    "\n",
    "Now we can use the variants to train our model using the `TrainVariantAnnotationsModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GATK jar /gatk/gatk-4.4.0.0/gatk-package-4.4.0.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gatk/gatk-4.4.0.0/gatk-package-4.4.0.0-local.jar TrainVariantAnnotationsModel --annotations-hdf5 /home/jupyter/notebooks/Output/output.extracted.annot.hdf5 -mode SNP -mode INDEL -O /home/jupyter/notebooks/Output/output.trained\n",
      "16:39:50.243 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-4.4.0.0/gatk-package-4.4.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "16:39:50.292 INFO  TrainVariantAnnotationsModel - ------------------------------------------------------------\n",
      "16:39:50.296 INFO  TrainVariantAnnotationsModel - The Genome Analysis Toolkit (GATK) v4.4.0.0\n",
      "16:39:50.296 INFO  TrainVariantAnnotationsModel - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "16:39:50.297 INFO  TrainVariantAnnotationsModel - Executing as jupyter@1d62e4d9ae5c on Linux v5.15.133+ amd64\n",
      "16:39:50.297 INFO  TrainVariantAnnotationsModel - Java runtime: OpenJDK 64-Bit Server VM v17.0.8.1+1-Ubuntu-0ubuntu120.04\n",
      "16:39:50.297 INFO  TrainVariantAnnotationsModel - Start Date/Time: January 10, 2024 at 4:39:50 PM UTC\n",
      "16:39:50.298 INFO  TrainVariantAnnotationsModel - ------------------------------------------------------------\n",
      "16:39:50.298 INFO  TrainVariantAnnotationsModel - ------------------------------------------------------------\n",
      "16:39:50.299 INFO  TrainVariantAnnotationsModel - HTSJDK Version: 3.0.5\n",
      "16:39:50.299 INFO  TrainVariantAnnotationsModel - Picard Version: 3.0.0\n",
      "16:39:50.300 INFO  TrainVariantAnnotationsModel - Built for Spark Version: 3.3.1\n",
      "16:39:50.300 INFO  TrainVariantAnnotationsModel - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "16:39:50.300 INFO  TrainVariantAnnotationsModel - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "16:39:50.301 INFO  TrainVariantAnnotationsModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "16:39:50.301 INFO  TrainVariantAnnotationsModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "16:39:50.301 INFO  TrainVariantAnnotationsModel - Deflater: IntelDeflater\n",
      "16:39:50.302 INFO  TrainVariantAnnotationsModel - Inflater: IntelInflater\n",
      "16:39:50.302 INFO  TrainVariantAnnotationsModel - GCS max retries/reopens: 20\n",
      "16:39:50.302 INFO  TrainVariantAnnotationsModel - Requester pays: disabled\n",
      "16:39:50.303 WARN  TrainVariantAnnotationsModel - \n",
      "\n",
      "\u001b[1m\u001b[31m   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "   Warning: TrainVariantAnnotationsModel is a BETA tool and is not yet ready for use in production\n",
      "\n",
      "   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n",
      "\n",
      "\n",
      "16:39:50.303 INFO  TrainVariantAnnotationsModel - Initializing engine\n",
      "16:39:50.304 INFO  TrainVariantAnnotationsModel - Done initializing engine\n",
      "16:39:52.543 INFO  TrainVariantAnnotationsModel - Running in PYTHON_IFOREST mode...\n",
      "16:39:52.544 INFO  TrainVariantAnnotationsModel - Starting training...\n",
      "16:39:52.557 INFO  HDF5Library - Trying to load HDF5 library from:\n",
      "\tjar:file:/gatk/gatk-4.4.0.0/gatk-package-4.4.0.0-local.jar!/org/broadinstitute/hdf5/libjhdf5.2.11.0.so\n",
      "16:39:52.630 INFO  H5 - HDF5 library: \n",
      "16:39:52.631 INFO  H5 -  successfully loaded.\n",
      "16:39:52.726 INFO  TrainVariantAnnotationsModel - Training SNP model with 11026 training sites x 5 annotations [FS, MQRankSum, QD, ReadPosRankSum, SOR]...\n",
      "16:39:55.051 INFO  TrainVariantAnnotationsModel - SNP model trained and serialized with output prefix \"/home/jupyter/notebooks/Output/output.trained.snp\".\n",
      "16:39:55.051 INFO  TrainVariantAnnotationsModel - Scoring 11026 SNP training sites...\n",
      "16:39:56.077 INFO  TrainVariantAnnotationsModel - SNP training scores written to /home/jupyter/notebooks/Output/output.trained.snp.trainingScores.hdf5.\n",
      "16:39:56.084 INFO  TrainVariantAnnotationsModel - Scoring 6581 SNP calibration sites...\n",
      "16:39:57.029 INFO  TrainVariantAnnotationsModel - SNP calibration scores written to /home/jupyter/notebooks/Output/output.trained.snp.calibrationScores.hdf5.\n",
      "16:39:57.041 INFO  TrainVariantAnnotationsModel - Training INDEL model with 1327 training sites x 5 annotations [FS, MQRankSum, QD, ReadPosRankSum, SOR]...\n",
      "16:39:58.034 INFO  TrainVariantAnnotationsModel - INDEL model trained and serialized with output prefix \"/home/jupyter/notebooks/Output/output.trained.indel\".\n",
      "16:39:58.035 INFO  TrainVariantAnnotationsModel - Scoring 1327 INDEL training sites...\n",
      "16:39:58.843 INFO  TrainVariantAnnotationsModel - INDEL training scores written to /home/jupyter/notebooks/Output/output.trained.indel.trainingScores.hdf5.\n",
      "16:39:58.845 INFO  TrainVariantAnnotationsModel - Scoring 1327 INDEL calibration sites...\n",
      "16:39:59.655 INFO  TrainVariantAnnotationsModel - INDEL calibration scores written to /home/jupyter/notebooks/Output/output.trained.indel.calibrationScores.hdf5.\n",
      "16:39:59.655 INFO  TrainVariantAnnotationsModel - TrainVariantAnnotationsModel complete.\n",
      "16:39:59.655 INFO  TrainVariantAnnotationsModel - Shutting down engine\n",
      "[January 10, 2024 at 4:39:59 PM UTC] org.broadinstitute.hellbender.tools.walkers.vqsr.scalable.TrainVariantAnnotationsModel done. Elapsed time: 0.16 minutes.\n",
      "Runtime.totalMemory()=113246208\n"
     ]
    }
   ],
   "source": [
    "! gatk TrainVariantAnnotationsModel \\\n",
    "   --annotations-hdf5 $LOCAL_DATA_DIR/Output/output.extracted.annot.hdf5 \\\n",
    "   -mode SNP \\\n",
    "   -mode INDEL \\\n",
    "   -O $LOCAL_DATA_DIR/Output/output.trained\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, we will score the Variant Annotations\n",
    "\n",
    "Now we can score the variants in our model using the `ScoreVariantAnnotations`.\n",
    "\n",
    "Note that the filtering threshold has been set:\n",
    "  --snp-calibration-sensitivity-threshold 0.997\n",
    "  --indel-calibration-sensitivity-threshold 0.997\n",
    "\n",
    "Make sure that the resources used here match those from the extraaction step above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GATK jar /gatk/gatk-package-4.5.0.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gatk/gatk-package-4.5.0.0-local.jar ScoreVariantAnnotations -mode SNP -mode INDEL -V gs://gatk-tutorials/workshop_2002/2-germline/CNNScoreVariants/vcfs/g94982_b37_chr20_1m_15871.vcf.gz -O /home/jupyter/notebooks/Output/output.score --model-prefix /home/jupyter/notebooks/Output/output.trained -A QD -A FS -A SOR -A MQRankSum -A ReadPosRankSum --resource:hapmap,training=true,calibration=true /home/jupyter/notebooks/2-germline/resources/hapmap_3.3.b37.chr20.vcf.gz --resource:omni,training=true,calibration=true /home/jupyter/notebooks/2-germline/resources/1000G_omni2.5.b37.chr20.vcf.gz --resource:1000G,training=true /home/jupyter/notebooks/2-germline/resources/1000G_phase1.snps.high_confidence.b37.chr20.vcf.gz --resource:mills,training=true,calibration=true /home/jupyter/notebooks/2-germline/resources/Mills_and_1000G_gold_standard.indels.b37.chr20.vcf.gz --resource:axiomPoly,training=true,calibration=true /home/jupyter/notebooks/2-germline/resources/Axiom_Exome_Plus.genotypes.all_populations.poly.chr20.vcf.gz --resource:extracted,extracted=true /home/jupyter/notebooks/Output/output.extracted.vcf.gz --snp-calibration-sensitivity-threshold 0.997 --indel-calibration-sensitivity-threshold 0.997\n",
      "05:01:45.073 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.5.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "05:01:45.225 INFO  ScoreVariantAnnotations - ------------------------------------------------------------\n",
      "05:01:45.228 INFO  ScoreVariantAnnotations - The Genome Analysis Toolkit (GATK) v4.5.0.0\n",
      "05:01:45.228 INFO  ScoreVariantAnnotations - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "05:01:45.228 INFO  ScoreVariantAnnotations - Executing as root@6fffd5f5c26a on Linux v6.5.11-linuxkit amd64\n",
      "05:01:45.228 INFO  ScoreVariantAnnotations - Java runtime: OpenJDK 64-Bit Server VM v17.0.9+9-Ubuntu-122.04\n",
      "05:01:45.229 INFO  ScoreVariantAnnotations - Start Date/Time: January 19, 2024 at 5:01:45 AM GMT\n",
      "05:01:45.229 INFO  ScoreVariantAnnotations - ------------------------------------------------------------\n",
      "05:01:45.229 INFO  ScoreVariantAnnotations - ------------------------------------------------------------\n",
      "05:01:45.231 INFO  ScoreVariantAnnotations - HTSJDK Version: 4.1.0\n",
      "05:01:45.231 INFO  ScoreVariantAnnotations - Picard Version: 3.1.1\n",
      "05:01:45.231 INFO  ScoreVariantAnnotations - Built for Spark Version: 3.5.0\n",
      "05:01:45.231 INFO  ScoreVariantAnnotations - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "05:01:45.231 INFO  ScoreVariantAnnotations - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "05:01:45.232 INFO  ScoreVariantAnnotations - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "05:01:45.232 INFO  ScoreVariantAnnotations - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "05:01:45.232 INFO  ScoreVariantAnnotations - Deflater: IntelDeflater\n",
      "05:01:45.232 INFO  ScoreVariantAnnotations - Inflater: IntelInflater\n",
      "05:01:45.233 INFO  ScoreVariantAnnotations - GCS max retries/reopens: 20\n",
      "05:01:45.233 INFO  ScoreVariantAnnotations - Requester pays: disabled\n",
      "05:01:45.233 WARN  ScoreVariantAnnotations - \n",
      "\n",
      "\u001b[1m\u001b[31m   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "   Warning: ScoreVariantAnnotations is a BETA tool and is not yet ready for use in production\n",
      "\n",
      "   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n",
      "\n",
      "\n",
      "05:01:45.234 INFO  ScoreVariantAnnotations - Initializing engine\n",
      "05:01:45.302 INFO  ScoreVariantAnnotations - Shutting down engine\n",
      "[January 19, 2024 at 5:01:45 AM GMT] org.broadinstitute.hellbender.tools.walkers.vqsr.scalable.ScoreVariantAnnotations done. Elapsed time: 0.00 minutes.\n",
      "Runtime.totalMemory()=116391936\n",
      "***********************************************************************\n",
      "\n",
      "A USER ERROR has occurred: Couldn't read file file:///home/jupyter/notebooks/2-germline/resources/hapmap_3.3.b37.chr20.vcf.gz. Error was: It doesn't exist.\n",
      "\n",
      "***********************************************************************\n",
      "Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.\n"
     ]
    }
   ],
   "source": [
    "! gatk ScoreVariantAnnotations \\\n",
    "    -mode SNP \\\n",
    "    -mode INDEL \\\n",
    "    -V $VCF_FILE \\\n",
    "    -O $LOCAL_DATA_DIR/Output/output.score \\\n",
    "    --model-prefix $LOCAL_DATA_DIR/Output/output.trained \\\n",
    "    -A QD \\\n",
    "    -A FS \\\n",
    "    -A SOR \\\n",
    "    -A MQRankSum \\\n",
    "    -A ReadPosRankSum \\\n",
    "    --resource:hapmap,training=true,calibration=true $LOCAL_DATA_DIR/2-germline/resources/hapmap_3.3.b37.chr20.vcf.gz \\\n",
    "    --resource:omni,training=true,calibration=true $LOCAL_DATA_DIR/2-germline/resources/1000G_omni2.5.b37.chr20.vcf.gz \\\n",
    "    --resource:1000G,training=true $LOCAL_DATA_DIR/2-germline/resources/1000G_phase1.snps.high_confidence.b37.chr20.vcf.gz \\\n",
    "    --resource:mills,training=true,calibration=true $LOCAL_DATA_DIR/2-germline/resources/Mills_and_1000G_gold_standard.indels.b37.chr20.vcf.gz \\\n",
    "    --resource:axiomPoly,training=true,calibration=true $LOCAL_DATA_DIR/2-germline/resources/Axiom_Exome_Plus.genotypes.all_populations.poly.chr20.vcf.gz \\\n",
    "    --resource:extracted,extracted=true $LOCAL_DATA_DIR/Output/output.extracted.vcf.gz \\\n",
    "    --snp-calibration-sensitivity-threshold 0.997 \\\n",
    "    --indel-calibration-sensitivity-threshold 0.997\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat $LOCAL_DATA_DIR/Output/output.extracted.annot.hdf5\n",
    "TODO:\n",
    "import h5py    \n",
    "import numpy as np    \n",
    "f1 = h5py.File(file_name,'r+')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Unfiltered VCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GATK jar /gatk/gatk-package-4.5.0.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gatk/gatk-package-4.5.0.0-local.jar Concordance -truth gs://gatk-tutorials/workshop_2002/2-germline/CNNScoreVariants/vcfs/hg001_na12878_b37_truth.vcf.gz -eval gs://gatk-tutorials/workshop_2002/2-germline/CNNScoreVariants/vcfs/g94982_b37_chr20_1m_15871.vcf.gz -L 20:1000000-9467292 -S /home/jupyter/notebooks/Output/unfiltered_concordance.txt\n",
      "05:04:15.986 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.5.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "05:04:16.169 INFO  Concordance - ------------------------------------------------------------\n",
      "05:04:16.173 INFO  Concordance - The Genome Analysis Toolkit (GATK) v4.5.0.0\n",
      "05:04:16.173 INFO  Concordance - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "05:04:16.173 INFO  Concordance - Executing as root@6fffd5f5c26a on Linux v6.5.11-linuxkit amd64\n",
      "05:04:16.173 INFO  Concordance - Java runtime: OpenJDK 64-Bit Server VM v17.0.9+9-Ubuntu-122.04\n",
      "05:04:16.174 INFO  Concordance - Start Date/Time: January 19, 2024 at 5:04:15 AM GMT\n",
      "05:04:16.174 INFO  Concordance - ------------------------------------------------------------\n",
      "05:04:16.174 INFO  Concordance - ------------------------------------------------------------\n",
      "05:04:16.176 INFO  Concordance - HTSJDK Version: 4.1.0\n",
      "05:04:16.176 INFO  Concordance - Picard Version: 3.1.1\n",
      "05:04:16.176 INFO  Concordance - Built for Spark Version: 3.5.0\n",
      "05:04:16.177 INFO  Concordance - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "05:04:16.178 INFO  Concordance - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "05:04:16.178 INFO  Concordance - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "05:04:16.178 INFO  Concordance - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "05:04:16.179 INFO  Concordance - Deflater: IntelDeflater\n",
      "05:04:16.179 INFO  Concordance - Inflater: IntelInflater\n",
      "05:04:16.179 INFO  Concordance - GCS max retries/reopens: 20\n",
      "05:04:16.179 INFO  Concordance - Requester pays: disabled\n",
      "05:04:16.180 INFO  Concordance - Initializing engine\n",
      "05:04:41.262 INFO  FeatureManager - Using codec VCFCodec to read file gs://gatk-tutorials/workshop_2002/2-germline/CNNScoreVariants/vcfs/hg001_na12878_b37_truth.vcf.gz\n",
      "05:04:51.423 INFO  IntervalArgumentCollection - Processing 8467293 bp from intervals\n",
      "05:05:06.993 INFO  FeatureManager - Using codec VCFCodec to read file gs://gatk-tutorials/workshop_2002/2-germline/CNNScoreVariants/vcfs/g94982_b37_chr20_1m_15871.vcf.gz\n",
      "05:05:14.098 INFO  Concordance - Done initializing engine\n",
      "05:05:14.146 INFO  ProgressMeter - Starting traversal\n",
      "05:05:14.149 INFO  ProgressMeter -        Current Locus  Elapsed Minutes     Records Processed   Records/Minute\n",
      "05:05:20.406 INFO  ProgressMeter -           20:8785648              0.1                 15916         153358.0\n",
      "05:05:20.409 INFO  ProgressMeter - Traversal complete. Processed 15916 total records in 0.1 minutes.\n",
      "05:05:20.434 INFO  Concordance - Shutting down engine\n",
      "[January 19, 2024 at 5:05:20 AM GMT] org.broadinstitute.hellbender.tools.walkers.validation.Concordance done. Elapsed time: 1.08 minutes.\n",
      "Runtime.totalMemory()=264241152\n",
      "Tool returned:\n",
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!gatk Concordance \\\n",
    "-truth $BASE_DATA_DIR/2-germline/CNNScoreVariants/vcfs/hg001_na12878_b37_truth.vcf.gz \\\n",
    "-eval $VCF_FILE \\\n",
    "-L 20:1000000-9467292 \\\n",
    "-S $LOCAL_DATA_DIR/Output/unfiltered_concordance.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate VETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GATK jar /gatk/gatk-package-4.5.0.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gatk/gatk-package-4.5.0.0-local.jar Concordance -truth gs://gatk-tutorials/workshop_2002/2-germline/CNNScoreVariants/vcfs/hg001_na12878_b37_truth.vcf.gz -eval /home/jupyter/notebooks/Output/output.score.vcf.gz -L 20:1000000-9467292 -S /home/jupyter/notebooks/Output/vets_concordance.txt\n",
      "05:05:23.437 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.5.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "05:05:23.606 INFO  Concordance - ------------------------------------------------------------\n",
      "05:05:23.609 INFO  Concordance - The Genome Analysis Toolkit (GATK) v4.5.0.0\n",
      "05:05:23.609 INFO  Concordance - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "05:05:23.609 INFO  Concordance - Executing as root@6fffd5f5c26a on Linux v6.5.11-linuxkit amd64\n",
      "05:05:23.609 INFO  Concordance - Java runtime: OpenJDK 64-Bit Server VM v17.0.9+9-Ubuntu-122.04\n",
      "05:05:23.609 INFO  Concordance - Start Date/Time: January 19, 2024 at 5:05:23 AM GMT\n",
      "05:05:23.610 INFO  Concordance - ------------------------------------------------------------\n",
      "05:05:23.610 INFO  Concordance - ------------------------------------------------------------\n",
      "05:05:23.611 INFO  Concordance - HTSJDK Version: 4.1.0\n",
      "05:05:23.611 INFO  Concordance - Picard Version: 3.1.1\n",
      "05:05:23.612 INFO  Concordance - Built for Spark Version: 3.5.0\n",
      "05:05:23.613 INFO  Concordance - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "05:05:23.613 INFO  Concordance - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "05:05:23.613 INFO  Concordance - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "05:05:23.613 INFO  Concordance - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "05:05:23.614 INFO  Concordance - Deflater: IntelDeflater\n",
      "05:05:23.614 INFO  Concordance - Inflater: IntelInflater\n",
      "05:05:23.614 INFO  Concordance - GCS max retries/reopens: 20\n",
      "05:05:23.614 INFO  Concordance - Requester pays: disabled\n",
      "05:05:23.615 INFO  Concordance - Initializing engine\n",
      "05:05:47.933 INFO  FeatureManager - Using codec VCFCodec to read file gs://gatk-tutorials/workshop_2002/2-germline/CNNScoreVariants/vcfs/hg001_na12878_b37_truth.vcf.gz\n",
      "05:05:55.948 INFO  IntervalArgumentCollection - Processing 8467293 bp from intervals\n",
      "05:06:02.368 INFO  Concordance - Shutting down engine\n",
      "[January 19, 2024 at 5:06:02 AM GMT] org.broadinstitute.hellbender.tools.walkers.validation.Concordance done. Elapsed time: 0.65 minutes.\n",
      "Runtime.totalMemory()=166723584\n",
      "***********************************************************************\n",
      "\n",
      "A USER ERROR has occurred: Couldn't read file file:///home/jupyter/notebooks/Output/output.score.vcf.gz. Error was: It doesn't exist.\n",
      "\n",
      "***********************************************************************\n",
      "Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.\n"
     ]
    }
   ],
   "source": [
    "!gatk Concordance \\\n",
    "-truth $BASE_DATA_DIR/2-germline/CNNScoreVariants/vcfs/hg001_na12878_b37_truth.vcf.gz \\\n",
    "-eval $LOCAL_DATA_DIR/Output/output.score.vcf.gz \\\n",
    "-L 20:1000000-9467292 \\\n",
    "-S $LOCAL_DATA_DIR/Output/vets_concordance.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now look at how precision goes up (and sensitivity goes down) as we filter.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Define a quick tool to generate an F1 score from the concordance report <collapsed for ease of reading>\n",
    "\n",
    "def print_f1_scores(concordance_file):\n",
    "    with open(concordance_file, 'r') as f:\n",
    "        # Skip header:\n",
    "        f.readline()\n",
    "        # Get SNP scores:\n",
    "        _, tp, fp, fn, _, _ = f.readline().split(\"\\t\")\n",
    "        snp_f1 = (2*int(tp))/((2*int(tp))+int(fp)+int(fn))\n",
    "        # Get INDEL scores:\n",
    "        _, tp, fp, fn, _, _ = f.readline().split(\"\\t\")\n",
    "        indel_f1 = (2*int(tp))/((2*int(tp))+int(fp)+int(fn))\n",
    "    ff=\".5f\"\n",
    "    print(f\"SNP F1:\\t\\t{snp_f1:{ff}}\\nINDEL F1:\\t{indel_f1:{ff}}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type\tTP\tFP\tFN\tRECALL\tPRECISION\n",
      "SNP\t10715\t1218\t558\t0.951\t0.898\n",
      "INDEL\t1615\t1024\t111\t0.936\t0.612\n",
      "\n",
      "SNP F1:\t\t0.92347\n",
      "INDEL F1:\t0.73998\n"
     ]
    }
   ],
   "source": [
    "!cat $LOCAL_DATA_DIR/Output/unfiltered_concordance.txt\n",
    "print()\n",
    "print_f1_scores(f\"{LOCAL_DATA_DIR}/Output/unfiltered_concordance.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: /home/jupyter/notebooks/Output/vets_concordance.txt: No such file or directory\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/jupyter/notebooks/Output/vets_concordance.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-dc56d270929d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cat $LOCAL_DATA_DIR/Output/vets_concordance.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint_f1_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{LOCAL_DATA_DIR}/Output/vets_concordance.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-fad995e78cd1>\u001b[0m in \u001b[0;36mprint_f1_scores\u001b[0;34m(concordance_file)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_f1_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcordance_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcordance_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;31m# Skip header:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/jupyter/notebooks/Output/vets_concordance.txt'"
     ]
    }
   ],
   "source": [
    "!cat $LOCAL_DATA_DIR/Output/vets_concordance.txt\n",
    "print()\n",
    "print_f1_scores(f\"{LOCAL_DATA_DIR}/Output/vets_concordance.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lt-iXAiQjvMz"
   },
   "source": [
    "---\n",
    "# Run the default 1D model on the VCF with CNNScoreVariants\n",
    "\n",
    "CNNScoreVariant is a pre-trained Convolutional Neural Network tool to score variants. This tool uses machine learning to differentiate between good variants and artifacts of the sequencing process, a fairly new approach that is especially effective at correctly calling indels. \n",
    "\n",
    "VQSR and Hard-filtering only take into account variant annotations. However, CNNScoreVariants 1D Model evaluates **annotations** AND **reference files**, plus or minus 64 bases from the variant. For example, it accounts for regions in the ref file that are difficult to sequence.\n",
    "\n",
    "To enable the models to accurately filter and score variants from VCF files, we **trained** on validated VCFs (from truth models including **SynDip, Genomes in a bottle, and Platinum Genomes**) with unvalidated VCFs aligned to different reference builds (**HG19, HG38**), sequenced on **different machines**, using **different protocols**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qMvcrZ6pjvMz",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GATK jar /gatk/gatk-4.4.0.0/gatk-package-4.4.0.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gatk/gatk-4.4.0.0/gatk-package-4.4.0.0-local.jar CNNScoreVariants -V gs://gatk-tutorials/workshop_2002/2-germline/CNNScoreVariants/vcfs/g94982_b37_chr20_1m_15871.vcf.gz -O /home/jupyter/notebooks/Output/my_1d_cnn_scored.vcf -R gs://gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta\n",
      "22:02:26.982 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-4.4.0.0/gatk-package-4.4.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "22:02:27.030 INFO  CNNScoreVariants - ------------------------------------------------------------\n",
      "22:02:27.034 INFO  CNNScoreVariants - The Genome Analysis Toolkit (GATK) v4.4.0.0\n",
      "22:02:27.034 INFO  CNNScoreVariants - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "22:02:27.035 INFO  CNNScoreVariants - Executing as jupyter@523be06428f5 on Linux v5.15.133+ amd64\n",
      "22:02:27.035 INFO  CNNScoreVariants - Java runtime: OpenJDK 64-Bit Server VM v17.0.8.1+1-Ubuntu-0ubuntu120.04\n",
      "22:02:27.035 INFO  CNNScoreVariants - Start Date/Time: January 9, 2024 at 10:02:26 PM UTC\n",
      "22:02:27.036 INFO  CNNScoreVariants - ------------------------------------------------------------\n",
      "22:02:27.036 INFO  CNNScoreVariants - ------------------------------------------------------------\n",
      "22:02:27.037 INFO  CNNScoreVariants - HTSJDK Version: 3.0.5\n",
      "22:02:27.037 INFO  CNNScoreVariants - Picard Version: 3.0.0\n",
      "22:02:27.037 INFO  CNNScoreVariants - Built for Spark Version: 3.3.1\n",
      "22:02:27.038 INFO  CNNScoreVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "22:02:27.038 INFO  CNNScoreVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "22:02:27.038 INFO  CNNScoreVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "22:02:27.039 INFO  CNNScoreVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "22:02:27.039 INFO  CNNScoreVariants - Deflater: IntelDeflater\n",
      "22:02:27.039 INFO  CNNScoreVariants - Inflater: IntelInflater\n",
      "22:02:27.040 INFO  CNNScoreVariants - GCS max retries/reopens: 20\n",
      "22:02:27.040 INFO  CNNScoreVariants - Requester pays: disabled\n",
      "22:02:27.041 INFO  CNNScoreVariants - Initializing engine\n",
      "22:02:29.061 INFO  FeatureManager - Using codec VCFCodec to read file gs://gatk-tutorials/workshop_2002/2-germline/CNNScoreVariants/vcfs/g94982_b37_chr20_1m_15871.vcf.gz\n",
      "22:02:29.660 INFO  CNNScoreVariants - Done initializing engine\n",
      "22:02:29.662 INFO  NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/gatk/gatk-4.4.0.0/gatk-package-4.4.0.0-local.jar!/com/intel/gkl/native/libgkl_utils.so\n",
      "22:02:32.425 INFO  CNNScoreVariants - Using key:CNN_1D for CNN architecture:/tmp/1d_cnn_mix_train_full_bn.8548833449719942871.json and weights:/tmp/1d_cnn_mix_train_full_bn.13371743487165529672.hd5\n",
      "22:02:34.115 INFO  ProgressMeter - Starting traversal\n",
      "22:02:34.116 INFO  ProgressMeter -        Current Locus  Elapsed Minutes    Variants Processed  Variants/Minute\n",
      "22:02:34.117 INFO  CNNScoreVariants - Starting pass 0 through the variants\n",
      "22:02:45.075 INFO  ProgressMeter -           20:4497482              0.2                  7000          38342.2\n",
      "22:02:56.384 INFO  ProgressMeter -           20:7515748              0.4                 13000          35027.8\n",
      "22:02:59.998 WARN  IntelInflater - Zero Bytes Written : 0\n",
      "22:03:02.473 INFO  CNNScoreVariants - Finished pass 0 through the variants\n",
      "22:03:05.376 INFO  CNNScoreVariants - Starting pass 1 through the variants\n",
      "22:03:06.397 WARN  IntelInflater - Zero Bytes Written : 0\n",
      "22:03:06.415 INFO  ProgressMeter -           20:8840293              0.5                 31000          57586.9\n",
      "22:03:06.449 INFO  CNNScoreVariants - Finished pass 1 through the variants\n",
      "22:03:06.450 INFO  CNNScoreVariants - No variants filtered by: AllowAllVariantsVariantFilter\n",
      "22:03:06.452 INFO  CNNScoreVariants - 0 read(s) filtered by: AllowAllReadsReadFilter \n",
      "\n",
      "22:03:06.452 INFO  ProgressMeter -           20:8840293              0.5                 31742          58897.8\n",
      "22:03:06.454 INFO  ProgressMeter - Traversal complete. Processed 31742 total variants in 0.5 minutes.\n",
      "22:03:06.454 INFO  CNNScoreVariants - Done scoring variants with CNN.\n",
      "22:03:06.501 INFO  CNNScoreVariants - Shutting down engine\n",
      "[January 9, 2024 at 10:03:06 PM UTC] org.broadinstitute.hellbender.tools.walkers.vqsr.CNNScoreVariants done. Elapsed time: 0.66 minutes.\n",
      "Runtime.totalMemory()=274726912\n"
     ]
    }
   ],
   "source": [
    "!gatk CNNScoreVariants \\\n",
    "-V $VCF_FILE \\\n",
    "-O $LOCAL_DATA_DIR/Output/my_1d_cnn_scored.vcf \\\n",
    "-R gs://gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6PLJOxIYjvM1"
   },
   "source": [
    "The output VCF `my_1d_cnn_scored.vcf` will now have an INFO  field CNN_1D which corresponds to the score assigned by 1D model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XLWPcKDYjvM2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\tNA12878\r\n",
      "20\t1000072\trs6056638\tA\tG\t998.77\tPASS\tAC=2;AF=1.00;AN=2;CNN_1D=3.256;DB;DP=32;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;POSITIVE_TRAIN_SITE;QD=31.21;SOR=0.818;VQSLOD=20.79;culprit=MQ\tGT:AD:DP:GQ:PL\t1/1:0,32:32:96:1027,96,0\r\n",
      "20\t1000152\trs6056639\tC\tT\t678.77\tPASS\tAC=2;AF=1.00;AN=2;CNN_1D=2.313;DB;DP=28;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;POSITIVE_TRAIN_SITE;QD=24.24;SOR=0.693;VQSLOD=18.18;culprit=QD\tGT:AD:DP:GQ:PL\t1/1:0,28:28:81:707,81,0\r\n",
      "20\t1000179\trs6056640\tA\tC\t532.77\tPASS\tAC=2;AF=1.00;AN=2;CNN_1D=3.157;DB;DP=20;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;POSITIVE_TRAIN_SITE;QD=29.60;SOR=0.914;VQSLOD=21.14;culprit=MQ\tGT:AD:DP:GQ:PL\t1/1:0,18:18:54:561,54,0\r\n",
      "20\t1000303\trs6056641\tT\tC\t325.77\tPASS\tAC=2;AF=1.00;AN=2;CNN_1D=2.057;DB;DP=12;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;POSITIVE_TRAIN_SITE;QD=27.15;SOR=1.445;VQSLOD=17.39;culprit=QD\tGT:AD:DP:GQ:PL\t1/1:0,12:12:36:354,36,0\r\n",
      "grep: write error: Broken pipe\r\n",
      "cat: write error: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "!cat $LOCAL_DATA_DIR/Output/my_1d_cnn_scored.vcf | grep -v '##' | head -5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kfJiQ9dVjvM5"
   },
   "source": [
    "## Apply filters to the VCF based on the CNN_1D score with the FilterVariantTranches tool\n",
    "\n",
    "After scoring, you can filter your VCF by applying a sensitivity threshold with the tool FilterVariantTranches. \n",
    "\n",
    "Note that here the threshold is set to 99.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VcUIL_DfjvM6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GATK jar /gatk/gatk-4.4.0.0/gatk-package-4.4.0.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gatk/gatk-4.4.0.0/gatk-package-4.4.0.0-local.jar FilterVariantTranches -V /home/jupyter/notebooks/Output/my_1d_cnn_scored.vcf --resource gs://gcp-public-data--broad-references/hg19/v0/1000G_omni2.5.b37.vcf.gz --resource gs://gcp-public-data--broad-references/hg19/v0/hapmap_3.3.b37.vcf.gz --info-key CNN_1D --snp-tranche 99.9 --indel-tranche 99.9 -O /home/jupyter/notebooks/Output/my_1d_filtered.vcf --invalidate-previous-filters\n",
      "22:03:11.315 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-4.4.0.0/gatk-package-4.4.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "22:03:11.372 INFO  FilterVariantTranches - ------------------------------------------------------------\n",
      "22:03:11.376 INFO  FilterVariantTranches - The Genome Analysis Toolkit (GATK) v4.4.0.0\n",
      "22:03:11.377 INFO  FilterVariantTranches - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "22:03:11.377 INFO  FilterVariantTranches - Executing as jupyter@523be06428f5 on Linux v5.15.133+ amd64\n",
      "22:03:11.377 INFO  FilterVariantTranches - Java runtime: OpenJDK 64-Bit Server VM v17.0.8.1+1-Ubuntu-0ubuntu120.04\n",
      "22:03:11.377 INFO  FilterVariantTranches - Start Date/Time: January 9, 2024 at 10:03:11 PM UTC\n",
      "22:03:11.378 INFO  FilterVariantTranches - ------------------------------------------------------------\n",
      "22:03:11.378 INFO  FilterVariantTranches - ------------------------------------------------------------\n",
      "22:03:11.379 INFO  FilterVariantTranches - HTSJDK Version: 3.0.5\n",
      "22:03:11.379 INFO  FilterVariantTranches - Picard Version: 3.0.0\n",
      "22:03:11.379 INFO  FilterVariantTranches - Built for Spark Version: 3.3.1\n",
      "22:03:11.380 INFO  FilterVariantTranches - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "22:03:11.380 INFO  FilterVariantTranches - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "22:03:11.380 INFO  FilterVariantTranches - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "22:03:11.381 INFO  FilterVariantTranches - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "22:03:11.381 INFO  FilterVariantTranches - Deflater: IntelDeflater\n",
      "22:03:11.381 INFO  FilterVariantTranches - Inflater: IntelInflater\n",
      "22:03:11.381 INFO  FilterVariantTranches - GCS max retries/reopens: 20\n",
      "22:03:11.382 INFO  FilterVariantTranches - Requester pays: disabled\n",
      "22:03:11.382 INFO  FilterVariantTranches - Initializing engine\n",
      "22:03:12.841 INFO  FeatureManager - Using codec VCFCodec to read file gs://gcp-public-data--broad-references/hg19/v0/1000G_omni2.5.b37.vcf.gz\n",
      "22:03:14.708 INFO  FeatureManager - Using codec VCFCodec to read file gs://gcp-public-data--broad-references/hg19/v0/hapmap_3.3.b37.vcf.gz\n",
      "22:03:15.637 INFO  FeatureManager - Using codec VCFCodec to read file file:///home/jupyter/notebooks/Output/my_1d_cnn_scored.vcf\n",
      "22:03:15.667 INFO  FilterVariantTranches - Done initializing engine\n",
      "22:03:15.731 INFO  ProgressMeter - Starting traversal\n",
      "22:03:15.731 INFO  ProgressMeter -        Current Locus  Elapsed Minutes    Variants Processed  Variants/Minute\n",
      "22:03:15.733 INFO  FilterVariantTranches - Starting pass 0 through the variants\n",
      "22:03:16.937 INFO  FilterVariantTranches - Finished pass 0 through the variants\n",
      "22:03:16.938 INFO  FilterVariantTranches - Found 12929 SNPs and 2932 indels with INFO score key:CNN_1D.\n",
      "22:03:16.938 INFO  FilterVariantTranches - Found 6669 SNPs and 1 indels in the resources.\n",
      "22:03:16.970 INFO  FilterVariantTranches - Starting pass 1 through the variants\n",
      "22:03:18.084 INFO  FilterVariantTranches - Finished pass 1 through the variants\n",
      "22:03:18.085 INFO  FilterVariantTranches - No variants filtered by: AllowAllVariantsVariantFilter\n",
      "22:03:18.087 INFO  FilterVariantTranches - 0 read(s) filtered by: AllowAllReadsReadFilter \n",
      "\n",
      "22:03:18.093 INFO  ProgressMeter -           20:8840293              0.0                 31742         808713.4\n",
      "22:03:18.093 INFO  ProgressMeter - Traversal complete. Processed 31742 total variants in 0.0 minutes.\n",
      "22:03:18.094 INFO  FilterVariantTranches - Filtered 303 SNPs out of 12929 and filtered 1453 indels out of 2932 with INFO score: CNN_1D.\n",
      "22:03:18.106 INFO  FilterVariantTranches - Shutting down engine\n",
      "[January 9, 2024 at 10:03:18 PM UTC] org.broadinstitute.hellbender.tools.walkers.vqsr.FilterVariantTranches done. Elapsed time: 0.11 minutes.\n",
      "Runtime.totalMemory()=1235222528\n"
     ]
    }
   ],
   "source": [
    "!gatk FilterVariantTranches \\\n",
    "-V $LOCAL_DATA_DIR/Output/my_1d_cnn_scored.vcf \\\n",
    "--resource gs://gcp-public-data--broad-references/hg19/v0/1000G_omni2.5.b37.vcf.gz \\\n",
    "--resource gs://gcp-public-data--broad-references/hg19/v0/hapmap_3.3.b37.vcf.gz \\\n",
    "--info-key CNN_1D \\\n",
    "--snp-tranche 99.7 \\\n",
    "--indel-tranche 99.7 \\\n",
    "-O $LOCAL_DATA_DIR/Output/my_1d_filtered.vcf \\\n",
    "--invalidate-previous-filters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gBVRBZErjvM8"
   },
   "source": [
    "**Now you have a neural network filtered VCF!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HiwNQ22EjvNA"
   },
   "source": [
    "## Evaluate the 1D Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H88wXEuNjvNB",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GATK jar /gatk/gatk-4.4.0.0/gatk-package-4.4.0.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gatk/gatk-4.4.0.0/gatk-package-4.4.0.0-local.jar Concordance -truth gs://gatk-tutorials/workshop_2002/2-germline/CNNScoreVariants/vcfs/hg001_na12878_b37_truth.vcf.gz -eval /home/jupyter/notebooks/Output/my_1d_filtered.vcf -L 20:1000000-9467292 -S /home/jupyter/notebooks/Output/my_1d_filtered_concordance.txt\n",
      "22:14:55.244 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-4.4.0.0/gatk-package-4.4.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "22:14:55.297 INFO  Concordance - ------------------------------------------------------------\n",
      "22:14:55.302 INFO  Concordance - The Genome Analysis Toolkit (GATK) v4.4.0.0\n",
      "22:14:55.302 INFO  Concordance - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "22:14:55.303 INFO  Concordance - Executing as jupyter@523be06428f5 on Linux v5.15.133+ amd64\n",
      "22:14:55.303 INFO  Concordance - Java runtime: OpenJDK 64-Bit Server VM v17.0.8.1+1-Ubuntu-0ubuntu120.04\n",
      "22:14:55.303 INFO  Concordance - Start Date/Time: January 9, 2024 at 10:14:55 PM UTC\n",
      "22:14:55.303 INFO  Concordance - ------------------------------------------------------------\n",
      "22:14:55.304 INFO  Concordance - ------------------------------------------------------------\n",
      "22:14:55.305 INFO  Concordance - HTSJDK Version: 3.0.5\n",
      "22:14:55.305 INFO  Concordance - Picard Version: 3.0.0\n",
      "22:14:55.305 INFO  Concordance - Built for Spark Version: 3.3.1\n",
      "22:14:55.306 INFO  Concordance - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "22:14:55.306 INFO  Concordance - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "22:14:55.306 INFO  Concordance - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "22:14:55.307 INFO  Concordance - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "22:14:55.307 INFO  Concordance - Deflater: IntelDeflater\n",
      "22:14:55.307 INFO  Concordance - Inflater: IntelInflater\n",
      "22:14:55.307 INFO  Concordance - GCS max retries/reopens: 20\n",
      "22:14:55.308 INFO  Concordance - Requester pays: disabled\n",
      "22:14:55.308 INFO  Concordance - Initializing engine\n",
      "22:14:56.897 INFO  FeatureManager - Using codec VCFCodec to read file gs://gatk-tutorials/workshop_2002/2-germline/CNNScoreVariants/vcfs/hg001_na12878_b37_truth.vcf.gz\n",
      "22:14:57.941 INFO  IntervalArgumentCollection - Processing 8467293 bp from intervals\n",
      "22:14:58.125 INFO  FeatureManager - Using codec VCFCodec to read file file:///home/jupyter/notebooks/Output/my_1d_filtered.vcf\n",
      "22:14:58.214 INFO  Concordance - Done initializing engine\n",
      "22:14:58.222 INFO  ProgressMeter - Starting traversal\n",
      "22:14:58.223 INFO  ProgressMeter -        Current Locus  Elapsed Minutes     Records Processed   Records/Minute\n",
      "22:14:59.385 INFO  ProgressMeter -           20:8805052              0.0                 15898         824442.5\n",
      "22:14:59.386 INFO  ProgressMeter - Traversal complete. Processed 15898 total records in 0.0 minutes.\n",
      "22:14:59.392 INFO  Concordance - Shutting down engine\n",
      "[January 9, 2024 at 10:14:59 PM UTC] org.broadinstitute.hellbender.tools.walkers.validation.Concordance done. Elapsed time: 0.07 minutes.\n",
      "Runtime.totalMemory()=939524096\n",
      "Tool returned:\n",
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!gatk Concordance \\\n",
    "-truth $BASE_DATA_DIR/2-germline/CNNScoreVariants/vcfs/hg001_na12878_b37_truth.vcf.gz \\\n",
    "-eval $LOCAL_DATA_DIR/Output/my_1d_filtered.vcf \\\n",
    "-L 20:1000000-9467292 \\\n",
    "-S $LOCAL_DATA_DIR/Output/my_1d_filtered_concordance.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JYSN59z9jvNG"
   },
   "source": [
    "**Now look at how precision goes up (and sensitivity goes down) as we filter.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o6x_2NBijvNH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type\tTP\tFP\tFN\tRECALL\tPRECISION\n",
      "SNP\t10715\t1218\t558\t0.951\t0.898\n",
      "INDEL\t1615\t1024\t111\t0.936\t0.612\n",
      "\n",
      "SNP F1:\t\t0.92347\n",
      "INDEL F1:\t0.73998\n"
     ]
    }
   ],
   "source": [
    "!cat $LOCAL_DATA_DIR/Output/unfiltered_concordance.txt\n",
    "print()\n",
    "print_f1_scores(f\"{LOCAL_DATA_DIR}/Output/unfiltered_concordance.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HhD1FtYwjvNJ",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type\tTP\tFP\tFN\tRECALL\tPRECISION\n",
      "SNP\t11204\t1422\t69\t0.994\t0.887\n",
      "INDEL\t1151\t338\t575\t0.667\t0.773\n",
      "\n",
      "SNP F1:\t\t0.93761\n",
      "INDEL F1:\t0.71602\n"
     ]
    }
   ],
   "source": [
    "!cat $LOCAL_DATA_DIR/Output/my_1d_filtered_concordance.txt\n",
    "print()\n",
    "print_f1_scores(f\"{LOCAL_DATA_DIR}/Output/my_1d_filtered_concordance.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can now compare the CNN and VETS based filtering approaches:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type\tTP\tFP\tFN\tRECALL\tPRECISION\n",
      "SNP\t10596\t1175\t677\t0.94\t0.9\n",
      "INDEL\t1608\t1016\t118\t0.932\t0.613\n",
      "\n",
      "SNP F1:\t\t0.91963\n",
      "INDEL F1:\t0.73931\n"
     ]
    }
   ],
   "source": [
    "!cat $LOCAL_DATA_DIR/Output/vets_concordance.txt\n",
    "print()\n",
    "print_f1_scores(f\"{LOCAL_DATA_DIR}/Output/vets_concordance.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this dataset with these thresholds we can see two things:\n",
    "1. The 1D-CNN is better for SNP refinement.\n",
    "2. VETS is better for INDEL refinement.\n",
    "\n",
    "Can you think of why this might be?\n",
    "\n",
    "How could we improve the performance of the 1D-CNN?  Of VETS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copy of 4-gatk-cnn-tutorial-python.ipynb",
   "provenance": [
    {
     "file_id": "1mLSVww2qFdpJYpZHD7p8haR_ek9dBbdQ",
     "timestamp": 1560189836154
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
